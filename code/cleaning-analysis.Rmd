---
title: 'Práctica 2: Limpieza y análisis de datos'
author: "Renán Freire, Manuel García"
date: "20/05/2021"
output:
  pdf_document: 
    toc: yes
    toc_depth: '2'
  html_document: 
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 2
---
```{r echo=FALSE, results=FALSE, message=FALSE, warning=FALSE}
library(dplyr)
library(VIM)
```

# Descripción del dataset

## Descripción

Siguiendo la línea del deporte e inspirados en la película “Moneyball”, se ha encontrado un dataset llamado “Baseball Databank” (https://www.kaggle.com/open-source-sports/baseball-databank), que contiene una extensa base de datos sobre béisbol recopilada por el periodista Sean Lahman divididos en archivos planos (csv) y entre los más importantes se tiene:

* Master.csv: Contiene datos biográficos de los jugadores, como por ejemplo: Nombres, apellidos, lugar de nacimiento, año de nacimiento. Cada jugador tiene un identificado “playerID”.
  
* Batting.csv: Este archivo contiene datos estadísticos de bateo (corridas, homerun, número de golpes, etc).
  
* Pitching: Este archivo contiene datos estadísticos de lanzamiento (jugos ganados, perdidos, etc).
  
* Fielding.csv - Este archivo contiene datos estadísticos de las diferentes habilidades para moverse en el campo y atrapar, parar, lanzar, etc.

* Salaries.csv. Este archivo contiene el salario de cada jugador de acuerdo al año, equipo y liga jugada.
      
Cada registro de los datasets explicados están vinculado a un jugador mediante su identificador “playerID” además de otros identificadores relacionados a otros catálogos.

## Importancia y Objetivo 

Para esta práctica se ha centrado en el béisbol, debido a su importancia en el ámbito del BigData, ya que año tras año, este deporte genera gran cantidad de datos estadísticos en base a su complejidad, debido a sus diferentes reglas de juego y las diferentes características que cada jugador debe desempeñar de acuerdo a su posición en el campo de juego. 

El objetivo para el cual usaremos los datos, está orientado a la predicción de los salarios de los bateadores y su dependencia con los datos de desempeño de cada jugador,  generando modelos a través de algoritmos aprendizaje supervisado. Entre las preguntas a resolver tenemos:

* Los números de homeruns, strikeout y golpes , tienen una correlación con el valor del salario?

* La edad de cada bateador además de los datos de desempeño (homeruns, strikeout y golpes) tienen una correlación con el valor del salario?
  
* Evaluar si los bateadores de Estados Unidos ganan más que los bateadores del resto del mundo.

# Integración y selección de los datos de interés a analizar.

## Integración de fuentes de datos

De acuerdo al análisis del conjunto de datos y a la problemática a resolver, planteada para esta práctica, vamos a trabajar con los datos biográficos de los jugadores que juegan en la posición de bateadores además de sus datos estadísticos y su salario. Para esto vamos a realizar una fusión horizontal y vertical de los archivos: master.csv, batting.csv, salaries.csv; mediante los identificadores: “playerID” que relaciona cada fuente con el jugador y "yearID" vincula los años de los diferentes datos de rendimiento y el salario correspondiente.

```{r}
# Lectura de fuente de datos necesitadas
dataPlayer <- read.csv('../dataset/Master.csv')
print("[*] Dimensiones")
dim(dataPlayer)
print("[*] Nombre Columnas")
colnames(dataPlayer)
```

La fuente de datos **Master.csv** tiene las siguientes dimensiones: 18846 registros y 24 columnas.



```{r}
# Lectura de fuente de datos necesitadas
dataBatting <- read.csv('../dataset/Batting.csv')
print("[*] Dimensiones")
dim(dataBatting)
print("[*] Nombre Columnas")
colnames(dataBatting)
```

La fuente de datos **Batting.csv** tiene las siguientes dimensiones: 101332 registros y 22 columnas.

```{r}
# Lectura de fuente de datos necesitadas
dataSalaries <- read.csv('../dataset/Salaries.csv')
print("[*] Dimensiones")
dim(dataSalaries)
print("[*] Nombre Columnas")
colnames(dataSalaries)
```

La fuente de datos **Salaries.csv** tiene las siguientes dimensiones: 25575 registros y 5 columnas.

```{r}
# Integración fuentes
mergeCols <- c("playerID", "yearID")

datasetBateadores <- merge(dataPlayer,dataSalaries,by="playerID")
datasetBateadores <- merge(dataBatting,datasetBateadores,by=mergeCols)
print("[*] Dimensiones")
dim(datasetBateadores)
print("[*] Nombre Columnas")
colnames(datasetBateadores)
```

El dataset final tiene las siguientes dimensiones: 27385 registros y 48 columnas.

## Selección de datos y reducción de dimensionalidad 

Una vez analizado el dataset final, se puede identificar datos perdidos (N.D) para los años iniciales, por lo tanto, para nuestro objetivo, vamos a seleccionar todos los jugadores de posición bateadores correspondiente a los años 2014, 2015, siendo estos los datos más actuales disponibles y como resultado tenemos un conjunto de datos de alta calidad sin valores perdidos. Además como se observa en la sección anterior, el dataset contiene una gran cantidad de atributos no relevantes para nuestro estudio, por lo tanto aplicamos la técnica de selección de subconjuntos de atributos para seleccionar datos de interés. En este caso se han identificado los siguientes atributos como relevantes ya que corresponden a los datos de desempeño de los bateadores e identificación personal de los mismos, que serán de utilidad para la predicción resultante: 

* yearID: Año de recopilación de datos de desempeño y salario. 

* playerID: Identificador del jugador.

* nameFirst: Nombre del jugador.

* nameLast: Apellido del jugador.

* birthCountry: País de nacimiento del jugador.

* birthYear: Año de nacimiento del jugador, posteriormente será trasformado a la edad actual.

* bats: Indica si el jugador es diestro o zurdo para coger el bat.

* R: Número de carreras de un jugador

* H: Número de golpes acertados con el bat. 

* HR: Número de homerun.

* SO: Número de strikes.

* Salary: Salario anual del jugador.

```{r}
# Selección de atributos de interés
datasetBateadores <-select(datasetBateadores, 'yearID','playerID','nameFirst', 'nameLast', 
                           'birthCountry', 'birthYear','bats','R','H','HR','SO','salary');
# Selección de instancias de acuerdo a los anios 2014,2015
datasetBateadores <- filter(datasetBateadores, yearID>2013 & yearID<2016)
head(datasetBateadores)
```

Para que los análisis posteriores puedan ser ejecutados son confusiones, se han renombrado el nombre de las columnas del dataset final, además el campo **birthYear** es trasformado a la edad actual del jugador. Todo este proceso se presenta a continuación:

```{r}
# Renombrar nombres de interés
names (datasetBateadores) = c('Anio', 'IdJugador','Nombre','Apellido','Pais','Edad','ManoBateo',
                              'Carreras','Golpes','HomeRun','Strikeouts','Salario')
# Transformar anio de nacimiento por edad
datasetBateadores$Edad <- 2021 - datasetBateadores$Edad
head(datasetBateadores, n=10)
```

Una vez realizado la selección de datos y la reducción de dimensionalidad, se ha descubierto que para ciertos jugadores del datastet tienen más de un registro para el mismo año, de acuerdo a  la documentación de Sea Lahman, estos datos se presentan de esa forma ya que corresponden a los datos estadísticos de un jugador que estuvo en diferentes equipos o ligas para el mismo año. Para solucionar esto, se va a fusionar los registros de ese jugador en una sola fila y los datos estadísticos de rendimiento y salario tendrán el valor de la media.

```{r}
# Se agrupan registros para el mismo jugador calculando la media de los datos estadisticos
datasetBateadores <- aggregate(cbind(Edad,Carreras,Golpes,HomeRun,Strikeouts,Salario) ~ Anio + IdJugador + Nombre + Apellido + Pais + ManoBateo, data = datasetBateadores, FUN = mean)
# Ordenar por idJugador
datasetBateadores <- datasetBateadores[order(datasetBateadores$IdJugador),]
head(datasetBateadores, n=10)
```


# Limpieza de datos

## Detección y tratamiento de valores perdidos

EL dataset final, no contiene datos perdidos o no definidos ya que en secciones anteriores se filtraron los datos para los años mas actuales debido a que los años más antiguos tenían un gran porcentaje de datos no definidos.

```{r}
# Valores perdidos determinados por N.A
colSums(is.na(datasetBateadores))
```

Sin embargo, después de realizar una inspección al conjunto de datos, se ha identificado un caso especial, donde existen registros con valor 0 en las variables **carreras, golpes, homerun, strikeout** y dicho jugador tiene asignado un salario. Debido a que una de nuestras preguntas iniciales consisten en determinar la relación del las variables de rendimiento con el valor del salario del jugador, vamos a imputar estos valores 0 de todas las variables antes mencionadas mediante el algoritmo del vecino más cercano KNN, siendo este el más eficaz.

Para esto vamos a asignar el valor *NA* a la variables indicadas cuyos registros cumplan la condición de que las cuatro variables (carreras, golpes, homerun, strikeout) sean igual a 0 y su valor de salario mayor a 0 y a continuación se procede a la imputación. El modelo KNN permite rellenar los registros con los valores *NA*, en base a las demás observaciones del dataset, promediando todos los puntos más cercanos. Esta implementación se puede observar a continuación, que consta de la identificación del número de casos con datos de rendimiento en 0, además se inspecciona la variable salario si posee valores en 0 y finalmente la inputación de valores.


```{r}
# Verificamos datos de rendimiento en 0
dfEstadisticasCero <- filter(datasetBateadores, Carreras==0 & Golpes==0 & HomeRun==0 & Strikeouts==0)
# Verificamos datos de salario en 0
dfSalarioCero <- filter(datasetBateadores, Salario==0)
# cosntruye dataframe de resultados
resultados <-data.frame(c(nrow(dfEstadisticasCero), nrow(dfSalarioCero)), c('DATOS RENDIMIENTO EN 0', 'DATOS SALRIOS EN 0'))
resultados <- setNames(resultados, c('Nro. Registros', 'Descripción'))
resultados
```


```{r}
# Obtener indices de los datos de rendimiento tengan todos 0 y presenten salario
indicesFiltros <- which(datasetBateadores$Golpes == 0 & datasetBateadores$HomeRun == 0 & datasetBateadores$Strikeouts == 0 & datasetBateadores$Carreras == 0
                        & datasetBateadores$Salario > 0)
# Reemplazar valores de 0 por NA para los indices extraídos
datasetBateadores$Golpes[indicesFiltros] <- NA
datasetBateadores$HomeRun[indicesFiltros] <- NA
datasetBateadores$Strikeouts[indicesFiltros] <- NA
datasetBateadores$Carreras[indicesFiltros] <- NA
# Verificamos valores NA
colSums(is.na(datasetBateadores))
```

```{r}
# Imputación de valores perdidos
datasetBateadores <- kNN(datasetBateadores)
head(datasetBateadores,n=10)
```

```{r}
# Eliminar columnas agregagdas por el método KNN usado para imputación
datasetBateadores <- datasetBateadores[ -c(13:24) ]
head(datasetBateadores, n=10)
```

## Tipos de variables

Después de haber limpiado los datos debemos verificar los tipos de datos de las diferentes columnas que conforman en el dataset, mediante la función de R **str()**, como se ve a continuación:

```{r}
str(datasetBateadores)
```

De acuerdo a la salida de esta función, tenemos que los datos estadísticos que se van a analizar son de tipo numérico, listos para los análisis posteriores. Estos valores serán formateados para que presenten solo un decimal.

```{r}
datasetBateadores$Golpes <- round(datasetBateadores$Golpes, digits = 2)
datasetBateadores$HomeRun <- round(datasetBateadores$HomeRun, digits = 2)
datasetBateadores$Strikeouts <- round(datasetBateadores$Strikeouts, digits = 2)
datasetBateadores$Carreras <- round(datasetBateadores$Carreras, digits = 2) 
head(datasetBateadores, n=10)
```


## Identificación y tratamiento de valores extremos.

Para nuestro dataset final vamos a identificar si existen valores extremos sobre las variables de tipo numérico, mediante gráficas de caja y bigote para cada variable implicada. A continuación se presentan las gŕaficas y los resultados obtenidos.

```{r}
par(mfrow=c(3,2))
boxplot(datasetBateadores$Golpes, main="BoxPlot Golpes", col="green")
outliersGolpes <- boxplot.stats(datasetBateadores$Golpes)$out

boxplot(datasetBateadores$HomeRun, main="BoxPlot HomeRun", col="blue")
outliersHomeRun <- boxplot.stats(datasetBateadores$HomeRun)$out

boxplot(datasetBateadores$Strikeouts, main="BoxPlot Strikeouts", col="red")
outliersStrikes <- boxplot.stats(datasetBateadores$Strikeouts)$out

boxplot(datasetBateadores$Carreras, main="BoxPlot Carreras", col="brown")
outliersCarreras <- boxplot.stats(datasetBateadores$Carreras)$out

boxplot(datasetBateadores$Salario, main="BoxPlot Salario", col="yellow")
outliersSalarios <- boxplot.stats(datasetBateadores$Salario)$out

boxplot(datasetBateadores$Edad, main="BoxPlot Edad", col="gray")
outliersEdad <- boxplot.stats(datasetBateadores$Edad)$out

```
De acuerdo a los gráficos, podemos identificar que la variable **Salario** tiene 146 valores extremos y la variable **Edad** contiene 29 valores extremos, debido a que sobrepasan el rango intercuatílico, en este caso el límite superior.  Estos valores han sido revisados aleatoriamente y contrastando con otras fuentes (https://www.spotrac.com/mlb/rankings/), podemos indicar que no se trata de valores atípicos, los datos son correctos y los consideraremos en el análisis final.

# Análisis de los datos.

## Selección de los grupos de datos que se quieren analizar/comparar (planificación de los análisis a aplicar).

## Comprobación de la normalidad y homogeneidad de la varianza.

## Aplicación de pruebas estadísticas para comparar los grupos de datos. En función de los datos y el objetivo del estudio, aplicar pruebas de contraste de hipótesis, correlaciones, regresiones, etc. Aplicar al menos tres métodos de análisis diferentes.

# Representación de los resultados a partir de tablas y gráficas.

# Resolución del problema. A partir de los resultados obtenidos, ¿cuáles son las conclusiones? ¿Los resultados permiten responder al problema?

